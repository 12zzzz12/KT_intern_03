{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744c7d1c",
   "metadata": {},
   "source": [
    "필요한 기능들 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bda2fea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import PIL\n",
    "import gc\n",
    "import psutil\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from math import ceil\n",
    "import math\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras import applications\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.activations import softmax\n",
    "from keras.activations import elu\n",
    "from keras.activations import relu\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import BatchNormalization #정규화\n",
    "# from tensorflow.keras.layers.GroupNormalization import BatchNormalization\n",
    "from tqdm import tqdm\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746c0176",
   "metadata": {},
   "source": [
    "# 이미지 load하고 픽셀로 바꿈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae0f0368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "melanoma  파일 길이 :  374\n",
      "melanoma  :  ./data/train/melanoma\\ISIC_0000002.jpg\n",
      "nevus  파일 길이 :  1372\n",
      "nevus  :  ./data/train/nevus\\ISIC_0000000.jpg\n",
      "nevus  :  ./data/train/nevus\\ISIC_0010558.jpg\n",
      "seborrheic_keratosis  파일 길이 :  254\n",
      "seborrheic_keratosis  :  ./data/train/seborrheic_keratosis\\ISIC_0012090.jpg\n",
      "ok 2000\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_dir = \"./data/train\"\n",
    "categories = [\"melanoma\", \"nevus\", \"seborrheic_keratosis\"]\n",
    "n_classes = len(categories)\n",
    "\n",
    "#이미지크기\n",
    "image_w = 224 \n",
    "image_h = 224\n",
    "\n",
    "#pixels = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "    \n",
    "    #one-hot 돌리기.\n",
    "    label = [0 for i in range(n_classes)]\n",
    "    label[idx] = 1\n",
    "    image_dir = data_dir + \"/\" + cat\n",
    "    \n",
    "    files = glob.glob(image_dir+\"/*.jpg\")\n",
    "    print(cat, \" 파일 길이 : \", len(files))\n",
    "    \n",
    "    for i, f in enumerate(files):\n",
    "        img = Image.open(f)\n",
    "        img = img.convert(\"RGB\")\n",
    "        img = img.resize((image_w, image_h))\n",
    "        data = np.asarray(img)\n",
    "\n",
    "        X.append(data)\n",
    "        y.append(label)\n",
    "\n",
    "        if i % 700 == 0: #중간확인출력\n",
    "            print(cat, \" : \", f)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "#1 0 0 0 이면 airplanes\n",
    "#0 1 0 0 이면 buddha 이런식\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "xy = (X_train, X_test, y_train, y_test)\n",
    "np.save('./numpy_data/multi_data.npy', xy)\n",
    "\n",
    "print(\"ok\", len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5194f735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 224, 224, 3)\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = np.load('./numpy_data/multi_data.npy', allow_pickle=True)\n",
    "print(X_train.shape)\n",
    "print(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9522d29",
   "metadata": {},
   "source": [
    "**----------------------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b469aff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle('/content/drive/My Drive/CS 412 PROJECT/data/data224x224.csv')\n",
    "# #df['image'] = df['image'].map(lambda img: img/255)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd63aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df['image'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7da8887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #features and labels are splitted\n",
    "# X = df['image']\n",
    "# y = df['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca8a3b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e363486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-validation split\n",
    "from keras.utils import np_utils\n",
    "trainx, valx, trainy, valy = train_test_split(X, y, test_size=0.03,random_state=41)\n",
    "testx = valx\n",
    "testy = valy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "356caa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #turning image vectors into arrays\n",
    "# trainx = np.asarray(trainx.tolist())\n",
    "# testx = np.asarray(testx.tolist())\n",
    "# valx = np.asarray(valx.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "675f6b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (113, 3)\n",
      "Shape after one-hot encoding:  (113, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "#encoding the categories using one hot encoding\n",
    "# print(\"Shape before one-hot encoding: \", trainy.shape)\n",
    "# trainy = np_utils.to_categorical(trainy, 3)\n",
    "# testy = np_utils.to_categorical(testy, 3)\n",
    "# valy = np_utils.to_categorical(valy, 3)\n",
    "# print(\"Shape after one-hot encoding: \", trainy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a5422c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (1940, 224, 224, 3)\n",
      "y_train shape (1940, 3)\n",
      "X_val shape (60, 224, 224, 3)\n",
      "y_val shape (60, 3)\n",
      "X_test shape (60, 224, 224, 3)\n",
      "y_test shape (60, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape\", trainx.shape)\n",
    "print(\"y_train shape\", trainy.shape)\n",
    "print(\"X_val shape\", valx.shape)\n",
    "print(\"y_val shape\", valy.shape)\n",
    "print(\"X_test shape\", testx.shape)\n",
    "print(\"y_test shape\", testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d4c375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping the arrays to fit the models\n",
    "trainx = trainx.reshape(trainx.shape[0], *(224, 224, 3))\n",
    "testx = testx.reshape(testx.shape[0], *(224, 224, 3))\n",
    "valx = valx.reshape(valx.shape[0], *(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4af5d15b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet import preprocess_input\n",
    "\n",
    "#choosing the generator and the differences that would happen in the generated images\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input, \n",
    "    rescale=1./255,\n",
    "    rotation_range=180,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    brightness_range=[0.5,1.5],\n",
    "    zoom_range=0.6,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "#choosing the generator and the differences that would happen in the generated images\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    preprocessing_function=preprocess_input,\n",
    "    brightness_range=[0.5,1.5])\n",
    "\n",
    "\n",
    "#generating additional data\n",
    "train_generator = train_datagen.flow(\n",
    "    trainx,\n",
    "    y=trainy,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    "    )\n",
    "\n",
    "#generating additional data\n",
    "valid_generator=test_datagen.flow(\n",
    "    valx,\n",
    "    y=valy,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c51e939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (1500, 224, 224, 3)\n",
      "y_train shape (1500, 3)\n",
      "X_train shape (1940, 224, 224, 3)\n",
      "y_train shape (1940, 3)\n",
      "Epoch 1/10\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.9123 - accuracy: 0.6093\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78333, saving model to ./model\\multi_img_classification.model\n",
      "INFO:tensorflow:Assets written to: ./model\\multi_img_classification.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 443s 5s/step - loss: 0.9123 - accuracy: 0.6093 - val_loss: 0.7776 - val_accuracy: 0.7833\n",
      "Epoch 2/10\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.6457 - accuracy: 0.7433\n",
      "Epoch 00002: val_accuracy did not improve from 0.78333\n",
      "94/94 [==============================] - 441s 5s/step - loss: 0.6457 - accuracy: 0.7433 - val_loss: 0.5216 - val_accuracy: 0.7833\n",
      "Epoch 3/10\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.5201 - accuracy: 0.7880\n",
      "Epoch 00003: val_accuracy improved from 0.78333 to 0.88333, saving model to ./model\\multi_img_classification.model\n",
      "INFO:tensorflow:Assets written to: ./model\\multi_img_classification.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 476s 5s/step - loss: 0.5201 - accuracy: 0.7880 - val_loss: 0.3585 - val_accuracy: 0.8833\n",
      "Epoch 4/10\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.4076 - accuracy: 0.8493\n",
      "Epoch 00004: val_accuracy improved from 0.88333 to 0.90000, saving model to ./model\\multi_img_classification.model\n",
      "INFO:tensorflow:Assets written to: ./model\\multi_img_classification.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 461s 5s/step - loss: 0.4076 - accuracy: 0.8493 - val_loss: 0.3072 - val_accuracy: 0.9000\n",
      "Epoch 5/10\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.3113 - accuracy: 0.8887\n",
      "Epoch 00005: val_accuracy did not improve from 0.90000\n",
      "94/94 [==============================] - 445s 5s/step - loss: 0.3113 - accuracy: 0.8887 - val_loss: 0.2650 - val_accuracy: 0.9000\n",
      "Epoch 6/10\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.2550 - accuracy: 0.9133\n",
      "Epoch 00006: val_accuracy improved from 0.90000 to 0.95000, saving model to ./model\\multi_img_classification.model\n",
      "INFO:tensorflow:Assets written to: ./model\\multi_img_classification.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 462s 5s/step - loss: 0.2550 - accuracy: 0.9133 - val_loss: 0.2058 - val_accuracy: 0.9500\n",
      "Epoch 7/10\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.1906 - accuracy: 0.9420 \n",
      "Epoch 00007: val_accuracy did not improve from 0.95000\n",
      "94/94 [==============================] - 2103s 23s/step - loss: 0.1906 - accuracy: 0.9420 - val_loss: 0.1891 - val_accuracy: 0.9500\n",
      "Epoch 8/10\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.1494 - accuracy: 0.9613\n",
      "Epoch 00008: val_accuracy did not improve from 0.95000\n",
      "94/94 [==============================] - 454s 5s/step - loss: 0.1494 - accuracy: 0.9613 - val_loss: 0.1911 - val_accuracy: 0.9500\n",
      "Epoch 9/10\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.1154 - accuracy: 0.9760\n",
      "Epoch 00009: val_accuracy improved from 0.95000 to 0.96667, saving model to ./model\\multi_img_classification.model\n",
      "INFO:tensorflow:Assets written to: ./model\\multi_img_classification.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "94/94 [==============================] - 491s 5s/step - loss: 0.1154 - accuracy: 0.9760 - val_loss: 0.1854 - val_accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 0.9833\n",
      "Epoch 00010: val_accuracy did not improve from 0.96667\n",
      "94/94 [==============================] - 478s 5s/step - loss: 0.0977 - accuracy: 0.9833 - val_loss: 0.1769 - val_accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "input_shape = (224,224,3)\n",
    "lr = 1e-5\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "base_model = ResNet50(include_top=False, input_shape= (224,224,3), weights = 'imagenet') #base model\n",
    "\n",
    "x = base_model.output\n",
    "\n",
    "x = GlobalAveragePooling2D()(x) #extra layers\n",
    "x = Dropout(0.35)(x) #to avoid overfitting\n",
    "predictions = Dense(3, activation= 'softmax')(x) #output dense layer, we used softmax because it is multiclass\n",
    "model = Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "\n",
    "model.compile(optimizer = Adam(lr) ,\n",
    "              loss = \"categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"]) #this is the comiler we used Adam with a given learning rate\n",
    "\n",
    "model_path = './model' + '/multi_img_classification.model'\n",
    "checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_accuracy', verbose=1, \n",
    "                             save_best_only=True, mode='max') #this is the function that saves the best epoch\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=10, \n",
    "                                   verbose=1, mode='max', min_lr=0.00001) #another overfitting measure\n",
    "                              \n",
    "                              \n",
    "callbacks_list = [checkpoint, reduce_lr]\n",
    "\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", Y_train.shape)\n",
    "print(\"X_train shape\", trainx.shape)\n",
    "print(\"y_train shape\", trainy.shape)\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,\n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    validation_data=(valx,valy), \n",
    "                    callbacks=[checkpoint])\n",
    "\n",
    "# history = model.fit_generator(train_generator,\n",
    "#                               steps_per_epoch = 600,\n",
    "#                               epochs = epochs,\n",
    "#                               validation_data = valid_generator,\n",
    "#                               callbacks= callbacks_list) #training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adf378c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
